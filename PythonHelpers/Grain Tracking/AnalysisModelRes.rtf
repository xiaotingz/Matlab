{\rtf1\ansi\ansicpg1252\cocoartf1671
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 CODE\
y = mig_abs_ot_bin\
X = X_ot.iloc[:, 9:16]\
xgb1 = XGBClassifier(\
                     learning_rate =0.1,\
                     n_estimators=1000,\
                     max_depth=3,\
                     min_child_weight=1,\
                     gamma=0,\
                     colsample_bytree=0.3,\
                     objective='multi:softmax',\
                     scale_pos_weight=1,\
                     seed=27\
                    )\
RES\
Test = [0.39694656 0.40831919 0.39319149 0.38533674 0.4037639 ]\
Train = [0.77444089 0.76810051 0.77016386 0.77366518 0.7738576 ]\
\
\
CODE\
y = mig_abs_ot_bin\
X = X_ot.iloc[:, 9:16]\
xgb1 = XGBClassifier(\
                     learning_rate =0.1,\
                     n_estimators=100,\
                     max_depth=3,\
                     min_child_weight=1,\
                     gamma=0,\
                     colsample_bytree=0.3,\
                     objective='multi:softmax',\
                     scale_pos_weight=1,\
                     seed=27\
                    )\
RES\
Test = [0.4351145  0.42614601 0.4306383  0.428815   0.42001711]\
Train = [0.47902023 0.47508518 0.47669717 0.48032334 0.47991498]\
\
\
CODE \
y = mig_abs_ot_bin\
X = X_ot\
xgb1 = XGBClassifier(\
                     learning_rate =0.1,\
                     n_estimators=100,\
                     max_depth=3,\
                     min_child_weight=1,\
                     gamma=0,\
                     colsample_bytree=0.3,\
                     objective='multi:softmax',\
                     scale_pos_weight=1,\
                     seed=27\
                    )\
RES\
Test = [0.42663274 0.42444822 0.42468085 0.42114237 0.42942686]\
Train = [0.50628328 0.5072402  0.50478825 0.50542438 0.5088204 ]\
\
\
CODE \
y = mig_abs_nearest_bin\
X = X_nearest\
xgb1 = XGBClassifier(\
                     learning_rate =0.1,\
                     n_estimators=100,\
                     max_depth=3,\
                     min_child_weight=1,\
                     gamma=0,\
                     colsample_bytree=0.3,\
                     objective='multi:softmax',\
                     scale_pos_weight=1,\
                     seed=27\
                    )\
RES\
Test = [0.41525424 0.41560645 0.41957447 0.41296928 0.41076003]\
Train = [0.48051948 0.48169434 0.48575074 0.48352816 0.48746281]\
\
\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\
CODE \
y = mig_abs_ot_bin\
X = X_nearest\
y_onehot = pd.get_dummies(y)\
rf = RandomForestClassifier(n_estimators = 1000, max_features=4, random_state = 42)\
RES\
Test = [0.0893617  0.08510638 0.08595745 0.11319149 0.08006814]\
Train = [1. 1. 1. 1. 1.]\
\
CODE \
y = mig_abs_ot_bin\
X = X_nearest\
y_onehot = pd.get_dummies(y)\
rf = RandomForestClassifier(n_estimators = 100, max_features=4, random_state = 42)\
RES\
[0.09617021 0.09531915 0.08680851 0.10212766 0.09199319]\
[0.99978719 1.         0.99978719 0.99978719 0.99978723]\
\
\
##########################################################################\
X = energy_grad.iloc[:, 1:]\
y = energy_grad.iloc[:, 0]\
y_onehot = pd.get_dummies(y)\
rf = RandomForestClassifier(n_estimators = 100, max_features=4, random_state = 42)\
[0.78515346 0.78586724 0.81156317 0.82084226 0.80142857]\
[1.         1.         0.99982152 0.99982152 0.99982156]\
\
\
X = energy_grad.iloc[:, 1:]\
y = energy_grad.iloc[:, 0]\
y_onehot = pd.get_dummies(y)\
rf = RandomForestClassifier(n_estimators = 1000, max_features=4, random_state = 42)\
[0.78729479 0.78729479 0.81870093 0.82084226 0.80142857]\
[1. 1. 1. 1. 1.]\
\
\
}